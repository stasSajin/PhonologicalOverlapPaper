---
title: "Experiment 1 All 3"
author: "Stas Sajin"
date: "March 27, 2016"
output: html_document
---

#Synopsis
The aim of this document is to provide all the analyses for Experiment 1 Overlap all 3. In this experiment, participants were presented with displays of 4 words, among which were the target, a high phonological competitor, a low phonological competitor, and a distractor. This document will only cover the diveregenece analyses.




####*Libraries*
Load the required libraries 
```{r, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(parallel)
library(doParallel)
library(tidyr)
library(gridExtra)
library(eyetrackingR)
```

####*Data Loading*
First, I load the data file indicating the trials that were removed for each subject.

```{r}
deletedTrials<-read.csv("delete.csv")
```

Now I load up the csv files with Exp1 data. There are two files (Exp1Part1 and Exp1Part2). Not all colums in those files are required. Only the following colums will be loaded in R, so as to preserve memory space. The colums are: RECORDING_SESSION_LABEL, IA_FIRST_RUN_START_TIME, IA_FIRST_RUN_START_TIME, IA_FIRST_RUN_END_TIME, IA_SECOND_RUN_START_TIME, IA_SECOND_RUN_END_TIME, IA_THIRD_RUN_START_TIME, IA_THIRD_RUN_END_TIME, IA_LABEL, RESPONSE_ACC, IA_DWELL_TIME, TRIAL_INDEX, target, RESPONSE_RT,trialtype,target, list, oldnewitem

```{r}
Part1 <- read.csv("Exp1Part1.csv", na.strings = c("."))[,c('RECORDING_SESSION_LABEL', 'IA_FIRST_RUN_START_TIME', 'IA_FIRST_RUN_START_TIME', 'IA_FIRST_RUN_END_TIME', 'IA_SECOND_RUN_START_TIME', 'IA_SECOND_RUN_END_TIME', 'IA_THIRD_RUN_START_TIME', 'IA_THIRD_RUN_END_TIME', 'IA_LABEL', 'RESPONSE_ACC', 'IA_DWELL_TIME', 'TRIAL_INDEX', 'target', 'RESPONSE_RT', 'trialtype','oldnewitem', 'MOUSE_TIME','DISPLAY_TIME')]

#now load up part 2
Part2 <- read.csv("Exp1Part2.csv", na.strings = c("."))[,c('RECORDING_SESSION_LABEL', 'IA_FIRST_RUN_START_TIME', 'IA_FIRST_RUN_START_TIME', 'IA_FIRST_RUN_END_TIME', 'IA_SECOND_RUN_START_TIME', 'IA_SECOND_RUN_END_TIME', 'IA_THIRD_RUN_START_TIME', 'IA_THIRD_RUN_END_TIME', 'IA_LABEL', 'RESPONSE_ACC', 'IA_DWELL_TIME', 'TRIAL_INDEX', 'target', 'RESPONSE_RT', 'trialtype','oldnewitem', 'MOUSE_TIME','DISPLAY_TIME')]

#combine part 1 and part 2 into one dataframe
EyeData<-rbind(Part1, Part2)
```

#*Data Cleaning and Pre-Processing*

There is one subject in the dataframe that was mistakenly mislabeled as an Experiment 1 subject by an RA (subject 11spe2). 

Right now we have a dataset with all the subjects that took part in Experiment 1. In the code below, I perform some preprocessing that aims to do the following: Remove bad trials (e.g., trials with a lot of off-screen fixations or trials in which the fixations don't start at the center of the screen or trials in which the tracking of the eye was not very good. The decision about which trials should be removed was done by two graduate students, Stas and Julie.) The deleted trials can be found in the deletedTrials file (the file does not contain trial 11 from subject 11spe2). 

```{r}
#this part of the code is not very effective; need to figure out later how to optimize it.
EyeData<-EyeData[!c(EyeData$RECORDING_SESSION_LABEL=="1sse1" & EyeData$TRIAL_INDEX==50),]
EyeData<-EyeData[!c(EyeData$RECORDING_SESSION_LABEL=="12spe1" & EyeData$TRIAL_INDEX==73),]
EyeData<-EyeData[!c(EyeData$RECORDING_SESSION_LABEL=="7spe1" & EyeData$TRIAL_INDEX==38),]
EyeData<-EyeData[!c(EyeData$RECORDING_SESSION_LABEL=="4tle1" & EyeData$TRIAL_INDEX==53),]
EyeData<-EyeData[!c(EyeData$RECORDING_SESSION_LABEL=="9spe1" & EyeData$TRIAL_INDEX==87),]
EyeData<-EyeData[!c(EyeData$RECORDING_SESSION_LABEL=="11spe2" & EyeData$TRIAL_INDEX==11),]
24/10904 #deleted trials
```


Only 6 trials have been deleted, which constitutes less than 0.2% of the total number of  trials. 

In the code below, I transform the NAs to zero, calculate the RT from the onset of the word display till participants clicked the mouse

```{r}
#change all the NAs to zeros
EyeData[is.na(EyeData)] <- 0
#Calculate RT from the display onset until the mouse click is made
EyeData$RESPONSE_RT<-EyeData$MOUSE_TIME-EyeData$DISPLAY_TIME
#check the dimentions of the dataset
#dim(EyeData)
#remove the MOUSE_TIME and DISPLAY_TIME variables
EyeData<-EyeData %>% select (1:16)

#rename the RECORDING_SESSION_LABEL into Subject
colnames(EyeData)[1] <- "Subject"
#examine colum names
#names(EyeData)
```

Examine the structure of the dataframe
```{r}
#str(EyeData)
```

Subset the experimental trials. This will remove all other trialtypes, such as FillerRel, FillerUnrel and Practice trials
```{r}
EyeData <- EyeData %>% filter(trialtype=="Exp")
```

Check subject accuracy
```{r}
SubjectAccuracy<- EyeData %>% group_by(Subject) %>%
    summarise(MeanAccuracy=mean(RESPONSE_ACC)) %>% 
    arrange(MeanAccuracy)
SubjectAccuracy
mean(SubjectAccuracy$MeanAccuracy)
```

Subject accuracy is very high (99.4%). Allmost all the subjects have 100% accuracy. Only 5 participants have a few incorrect trials.

Remove trials with incorrect accuracy
```{r}
CorrectEyeData<-EyeData %>% filter(RESPONSE_ACC==1)
#number of rows deleted
nrow(EyeData)-nrow(CorrectEyeData) #20 rows get deleted, which corresponds to 5 incorrect trials
20/3468 #about .57% of the data was deleted. 
```

Set up the start time and the end time dummy-coding of each run in the interest area. This creates colums where if a fixation exists during a run, then the run gets 1 (exists) or if there is no fixation in the IA during a run, then the coding is 0 (not exist)
```{r}
CorrectEyeData$Fststart <- ifelse(as.numeric(as.character(CorrectEyeData$IA_FIRST_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_FIRST_RUN_START_TIME)), 0) 
CorrectEyeData$Fstend <- ifelse(as.numeric(as.character(CorrectEyeData$IA_FIRST_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_FIRST_RUN_END_TIME)), 0)
CorrectEyeData$Secstart <- ifelse(as.numeric(as.character(CorrectEyeData$IA_SECOND_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_SECOND_RUN_START_TIME)), 0)
CorrectEyeData$Secend <- ifelse(as.numeric(as.character(CorrectEyeData$IA_SECOND_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_SECOND_RUN_END_TIME)), 0)
CorrectEyeData$Thirdstart <- ifelse(as.numeric(as.character(CorrectEyeData$IA_THIRD_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_THIRD_RUN_START_TIME)), 0)
CorrectEyeData$Thirdend <- ifelse(as.numeric(as.character(CorrectEyeData$IA_THIRD_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_THIRD_RUN_END_TIME)), 0)
```

Generate time bins from time 0 to time 6000 in 25 ms bins and assign them to the dataset
```{r}
time <- seq(0, 6000, by=25)
tmatrix <- matrix(nrow=nrow(CorrectEyeData), ncol=length(time))
dim(tmatrix)
```

Generate time vectors for each row and column for first, second, and third pass viewings 
so that viewing periods receive a viewing probability value of 1 

```{r, warning=FALSE}
registerDoParallel(3)
for(i in 1:nrow(tmatrix)) {
for(j in 1:length(time)) {

tmatrix[i,j] <-  ifelse(CorrectEyeData$Fststart[i] < time[j] & 
                CorrectEyeData$Fstend[i] > time[j] |CorrectEyeData$Secstart[i] <
                time[j] & CorrectEyeData$Secend[i] > time[j] | CorrectEyeData$Thirdstart[i] 
                < time[j] & CorrectEyeData$Thirdend[i]>time[j], 1,0)
} 
}
```

Combine the CleanEyeData with the time matrix
```{r}
CleanData <- cbind(CorrectEyeData, data.frame(tmatrix))
```

Assign time values to time bin columns
```{r}
colnames(CleanData)[23:263] <- seq(0, 6000, by=25)
```

Subset the dataset with only the necessary colums and remove anything in the memory that might be a memory hog
```{r}
CleanData <- CleanData[, -c(2:8,10,11,13,14, 17:22)]
```

Put the data in long-format and then calculate the proportion for each time bin for each subject
```{r}
CleanData<- CleanData %>% gather(time,value,6:246)
```


subset the time from display onset
```{r}
#change time into numeric
CleanData$time<-as.numeric(CleanData$time)
CleanDataSubset<-CleanData %>% filter(time>=1600 & time <=3200)

#change the tiem variable so that it starts at 0.
CleanDataSubset$time<-CleanDataSubset$time-1600

#The code below aims to identify which time-ranges within trials have trackloss. The code will sum up the value column. If it is 0, this means that there was no fixation to any interest areas and the trial had trackloss, if it is 1, then there was a fixation to one of the interest areas. 
library(plyr)
testSubset<- ddply(CleanDataSubset, c("Subject", "TRIAL_INDEX","time"), 
             transform, TrackLoss=sum(value))

###remove rows that have value of 0 and trackloss of 1; In other words, this removes the rows for the IA that had no fixation in them and that also had no trackloss
#for trials with trackloss, I also remove all the non-target rows.
testSubset2<-testSubset %>% filter(!c(value==0 & TrackLoss==1)) %>%
    filter(!c(IA_LABEL=="CompetitorHigh " & TrackLoss==0)) %>%
    filter(!c(IA_LABEL=="CompetitorLow " & TrackLoss==0)) %>%
    filter(!c(IA_LABEL=="UNREL2_IA " & TrackLoss==0))
#now we have a trackloss column; in the following step, I will create the AOI Columns
#first, create filled out empty colums
namevector<-c("Target","CompetitorHigh","CompetitorLow","Distractor")
testSubset2[,namevector]<-NA

#fillout the new AOI colums
testSubset3<- testSubset2 %>% mutate(
    Target=ifelse(c(IA_LABEL=="TARGET_IA " & TrackLoss==1),TRUE,FALSE),
    CompetitorHigh=ifelse(c(IA_LABEL=="CompetitorHigh " & TrackLoss==1),TRUE,FALSE), 
    CompetitorLow=ifelse(c(IA_LABEL=="CompetitorLow " & TrackLoss==1),TRUE,FALSE),
    Distractor=ifelse(c(IA_LABEL=="UNREL2_IA " & TrackLoss==1),TRUE,FALSE),
    TrackLoss=ifelse(TrackLoss==0,TRUE,FALSE))

#ok, so the dataset is in the right format; Time to perform the analyses
```

```{r}
EyeData <- make_eyetrackingr_data(testSubset3, 
                participant_column = "Subject",
                trial_column = "TRIAL_INDEX",
                time_column = "time",
                trackloss_column = "TrackLoss",
                aoi_columns = c('Target','CompetitorHigh','CompetitorLow','Distractor'),
                treat_non_aoi_looks_as_missing = FALSE)


response_time2 <- make_time_sequence_data(EyeData,
                        time_bin_size = 25, 
                        aois = c('Target','CompetitorHigh','CompetitorLow','Distractor'),
                        summarize_by = "Subject")

response_time2$AOI<-as.factor(response_time2$AOI)
```


```{r,cache=TRUE}
###########################Target vs Competitor Bootstrap Analysis
#filter out the competitor and the target
Filtered<-response_time2 %>% filter(AOI=="CompetitorHigh" | AOI=="CompetitorLow")
Filtered$AOI<-as.factor(as.character(Filtered$AOI))
Filtered$AOI<-relevel(Filtered$AOI, "CompetitorHigh")

###########Bootsrapped cluster-based permutation analysis#######

#Find the number of subjects and the t-threshold 
num_sub = length(unique((Filtered$Subject)))
threshold_t = qt(p = 1 - .05/2, 
                 df = num_sub-1) # pick threshold t based on alpha = .05 two tailed



df_timeclust <- make_time_cluster_data(Filtered, 
                                      test= "t.test", paired=TRUE,
                                      predictor_column = "AOI",
                                      threshold = -threshold_t) 
tstat<-plot(df_timeclust) +  ylab("T-Statistic") + theme_light()
summary(df_timeclust)

registerDoParallel(3)
clust_analysis <- analyze_time_clusters(df_timeclust, samples=10000, within_subj=TRUE, paired=TRUE) #

distribution<-plot(clust_analysis) + theme_light()

plotExp1<-grid.arrange(tstat, distribution, nrow=1, ncol=2)
grid.arrange(tstat, distribution, nrow=1, ncol=2)

ggsave(
  "HighvsLowCompExp1.png",
  plotExp1,
  width = 9.25,
  height = 6.25,
  dpi = 300
)

summary(clust_analysis)
```



Session Info
```{r}
sessionInfo()
```