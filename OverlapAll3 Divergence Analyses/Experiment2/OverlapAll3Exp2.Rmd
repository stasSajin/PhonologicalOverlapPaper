---
title: "Experiment 2 All 3"
author: "Stas Sajin and Julie Gregg"
date: "Jan 19, 2016"
output: html_document
---

#Synopsis
The aim of this document is to provide all the analyses for Experiment 2 Overlap all 3. In this experiment, participants were presented with displays of 4 words, among which were the target, a high orthographic competitor, a low orthographic competitor, and a distractor. The structure of the document will be as follows. These report covers only the divergence analyses

####*Libraries*
Load the required libraries 
```{r, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(parallel)
library(doParallel)
library(tidyr)
library(gridExtra)
library(eyetrackingR)
```

####*Data Loading*
First, I load the data file indicating the trials that were removed for each subject.

```{r}
deletedTrials<-read.csv("deleted.csv")
```

Now I load up the csv files with Exp1 data. There are 4 files (Exp2Part1 and Exp2Part2, Exp2Part3 and sub 11spe2). Not all colums in those files are required. Only the following colums will be loaded in R, so as to preserve memory space. The colums are: RECORDING_SESSION_LABEL, IA_FIRST_RUN_START_TIME, IA_FIRST_RUN_START_TIME, IA_FIRST_RUN_END_TIME, IA_SECOND_RUN_START_TIME, IA_SECOND_RUN_END_TIME, IA_THIRD_RUN_START_TIME, IA_THIRD_RUN_END_TIME, IA_LABEL, RESPONSE_ACC, IA_DWELL_TIME, TRIAL_INDEX, target, RESPONSE_RT,trialtype,target, list, oldnewitem

```{r}
Part1 <- read.csv("Exp2Part1.csv", na.strings = c("."))[,c('RECORDING_SESSION_LABEL', 'IA_FIRST_RUN_START_TIME', 'IA_FIRST_RUN_START_TIME', 'IA_FIRST_RUN_END_TIME', 'IA_SECOND_RUN_START_TIME', 'IA_SECOND_RUN_END_TIME', 'IA_THIRD_RUN_START_TIME', 'IA_THIRD_RUN_END_TIME', 'IA_LABEL', 'RESPONSE_ACC', 'IA_DWELL_TIME', 'TRIAL_INDEX', 'target', 'RESPONSE_RT', 'trialtype','oldnewitem', 'MOUSE_TIME','DISPLAY_TIME')]

#now load up part 2
Part2 <- read.csv("Exp2Part2.csv", na.strings = c("."))[,c('RECORDING_SESSION_LABEL', 'IA_FIRST_RUN_START_TIME', 'IA_FIRST_RUN_START_TIME', 'IA_FIRST_RUN_END_TIME', 'IA_SECOND_RUN_START_TIME', 'IA_SECOND_RUN_END_TIME', 'IA_THIRD_RUN_START_TIME', 'IA_THIRD_RUN_END_TIME', 'IA_LABEL', 'RESPONSE_ACC', 'IA_DWELL_TIME', 'TRIAL_INDEX', 'target', 'RESPONSE_RT', 'trialtype','oldnewitem', 'MOUSE_TIME','DISPLAY_TIME')]

Part3 <- read.csv("Exp2Part3.csv", na.strings = c("."))[,c('RECORDING_SESSION_LABEL', 'IA_FIRST_RUN_START_TIME', 'IA_FIRST_RUN_START_TIME', 'IA_FIRST_RUN_END_TIME', 'IA_SECOND_RUN_START_TIME', 'IA_SECOND_RUN_END_TIME', 'IA_THIRD_RUN_START_TIME', 'IA_THIRD_RUN_END_TIME', 'IA_LABEL', 'RESPONSE_ACC', 'IA_DWELL_TIME', 'TRIAL_INDEX', 'target', 'RESPONSE_RT', 'trialtype','oldnewitem', 'MOUSE_TIME','DISPLAY_TIME')]

#combine part 1 and part 2 and part 3 into one dataframe
EyeData<-rbind(Part1, Part2, Part3)
```

#*Data Cleaning and Pre-Processing*

Right now we have a dataset with all the subjects that took part in Experiment 2. In the code below, I perform some preprocessing that aims to do the following: Remove bad trials (e.g., trials with a lot of off-screen fixations or trials in which the fixations don't start at the center of the screen or trials in which the tracking of the eye was not very good. The decision about which trials should be removed was done by two graduate students, Stas and Julie.) The deleted trials can be found in the deletedTrials file. 

```{r}
#this part of the code is not very effective; need to figure out later how to optimize it.
EyeData<-EyeData[!c(EyeData$RECORDING_SESSION_LABEL=="17spe2" & EyeData$TRIAL_INDEX==45),]
EyeData<-EyeData[!c(EyeData$RECORDING_SESSION_LABEL=="15spe2" & EyeData$TRIAL_INDEX==85),]
EyeData<-EyeData[!c(EyeData$RECORDING_SESSION_LABEL=="9sre2" & EyeData$TRIAL_INDEX==21),]
EyeData<-EyeData[!c(EyeData$RECORDING_SESSION_LABEL=="1tle2" & EyeData$TRIAL_INDEX==69),]
EyeData<-EyeData[!c(EyeData$RECORDING_SESSION_LABEL=="9spe2" & EyeData$TRIAL_INDEX==18),]
20/12672 #deleted trials
```

Only 5 trials have been deleted, which constitutes less than .15% of the total number of trials. 

In the code below, I transform the NAs to zero, calculate the RT from the onset of the word display till the mouse click time is made.

```{r}

#change all the NAs to zeros
EyeData[is.na(EyeData)] <- 0
#Calculate RT from the display onset until the mouse click is made
EyeData$RESPONSE_RT<-EyeData$MOUSE_TIME-EyeData$DISPLAY_TIME
#check the dimentions of the dataset
dim(EyeData)
#remove the MOUSE_TIME and DISPLAY_TIME variables
EyeData<-EyeData %>% select (1:16)

#rename the RECORDING_SESSION_LABEL into Subject
colnames(EyeData)[1] <- "Subject"
#examine colum names
names(EyeData)
```

Examine the structure of the dataframe
```{r}
str(EyeData)
```

Subset the experimental trials. This will remove all other trialtypes, such as FillerRel, FillerUnrel and Practice trials
```{r}
EyeData <- EyeData %>% filter(trialtype=="Exp")
```

Check subject accuracy
```{r}
SubjectAccuracy<- EyeData %>% group_by(Subject) %>%
    summarise(MeanAccuracy=mean(RESPONSE_ACC)) %>% 
    arrange(MeanAccuracy)
SubjectAccuracy
mean(SubjectAccuracy$MeanAccuracy)
```

Subject accuracy is very high. Allmost all the subjects have 100% accuracy. Only 4 participants have a few incorrect trials. One subject however has relatively low accuracy (.89)

Remove trials with incorrect accuracy
```{r}
CorrectEyeData<-EyeData %>% filter(RESPONSE_ACC==1)
#number of rows deleted
nrow(EyeData)-nrow(CorrectEyeData) #28 rows get deleted, which corresponds to 7 incorrect trials
26/3468 #3840 .749% of the data was deleted from experimental trials. 
```

Set up the start time and the end time dummy-coding of each run in the interest area. This creates colums where if a fixation exists during a run, then the run gets 1 (exists) or if there is no fixation in the IA during a run, then the coding is 0 (not exist)

```{r}
CorrectEyeData$Fststart <- ifelse(as.numeric(as.character(CorrectEyeData$IA_FIRST_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_FIRST_RUN_START_TIME)), 0) 
CorrectEyeData$Fstend <- ifelse(as.numeric(as.character(CorrectEyeData$IA_FIRST_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_FIRST_RUN_END_TIME)), 0)
CorrectEyeData$Secstart <- ifelse(as.numeric(as.character(CorrectEyeData$IA_SECOND_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_SECOND_RUN_START_TIME)), 0)
CorrectEyeData$Secend <- ifelse(as.numeric(as.character(CorrectEyeData$IA_SECOND_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_SECOND_RUN_END_TIME)), 0)
CorrectEyeData$Thirdstart <- ifelse(as.numeric(as.character(CorrectEyeData$IA_THIRD_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_THIRD_RUN_START_TIME)), 0)
CorrectEyeData$Thirdend <- ifelse(as.numeric(as.character(CorrectEyeData$IA_THIRD_RUN_START_TIME)) > 0, as.numeric(as.character(CorrectEyeData$IA_THIRD_RUN_END_TIME)), 0)
```

Generate time bins from time 0 to time 6000 in 25 ms bins and assign them to the dataset
```{r}
time <- seq(0, 6000, by=25)
tmatrix <- matrix(nrow=nrow(CorrectEyeData), ncol=length(time))
dim(tmatrix)
```

Generate time vectors for each row and column for first, second, and third pass viewings 
so that viewing periods receive a viewing probability value of 1 

```{r, warning=FALSE}
registerDoParallel(3)
for(i in 1:nrow(tmatrix)) {
for(j in 1:length(time)) {

tmatrix[i,j] <-  ifelse(CorrectEyeData$Fststart[i] < time[j] & 
                CorrectEyeData$Fstend[i] > time[j] |CorrectEyeData$Secstart[i] <
                time[j] & CorrectEyeData$Secend[i] > time[j] | CorrectEyeData$Thirdstart[i] 
                < time[j] & CorrectEyeData$Thirdend[i]>time[j], 1,0)
} 
}
```

Combine the CleanEyeData with the time matrix
```{r}
CleanData <- cbind(CorrectEyeData, data.frame(tmatrix))
```

Assign time values to time bin columns
```{r}
colnames(CleanData)[23:263] <- seq(0, 6000, by=25)
```

Subset the dataset with only the necessary colums and remove anything in the memory that might be a memory hog
```{r}
CleanData <- CleanData[, -c(2:8,10,11,13,14, 17:22)]
```

Put the data in long-format and then calculate the proportion for each time bin for each subject
```{r}
CleanData<- CleanData %>% gather(time,value,6:246)
```


#subset the time from information onset
```{r}
#change time into numeric
CleanData$time<-as.numeric(CleanData$time)
CleanDataSubset<-CleanData %>% filter(time>=1600 & time <=3200)

#change the tiem variable so that it starts at 0 (from display onset.
CleanDataSubset$time<-CleanDataSubset$time-1600

#The code below aims to identify which time-ranges within trials have trackloss. The code will sum up the value column. If it is 0, this means that there was no fixation to any interest areas and the trial had trackloss, if it is 1, then there was a fixation to one of the interest areas. 
library(plyr)
testSubset<- ddply(CleanDataSubset, c("Subject", "TRIAL_INDEX","time"), 
             transform, TrackLoss=sum(value))

###remove rows that have value of 0 and trackloss of 1; In other words, this removes the rows for the IA that had no fixation in them and that also had no trackloss
#for trials with trackloss, I also remove all the non-target rows.
testSubset2<-testSubset %>% filter(!c(value==0 & TrackLoss==1)) %>%
    filter(!c(IA_LABEL=="CompetitorHigh " & TrackLoss==0)) %>%
    filter(!c(IA_LABEL=="CompetitorLow " & TrackLoss==0)) %>%
    filter(!c(IA_LABEL=="UNREL2_IA " & TrackLoss==0))
#now we have a trackloss column; in the following step, I will create the AOI Columns
#first, create filled out empty colums
namevector<-c("Target","CompetitorHigh","CompetitorLow","Distractor")
testSubset2[,namevector]<-NA

#fillout the new AOI colums
testSubset3<- testSubset2 %>% mutate(
    Target=ifelse(c(IA_LABEL=="TARGET_IA " & TrackLoss==1),TRUE,FALSE),
    CompetitorHigh=ifelse(c(IA_LABEL=="CompetitorHigh " & TrackLoss==1),TRUE,FALSE), 
    CompetitorLow=ifelse(c(IA_LABEL=="CompetitorLow " & TrackLoss==1),TRUE,FALSE),
    Distractor=ifelse(c(IA_LABEL=="UNREL2_IA " & TrackLoss==1),TRUE,FALSE),
    TrackLoss=ifelse(TrackLoss==0,TRUE,FALSE))

#ok, so the dataset is in the right format; Time to perform the analyses
```

```{r}
EyeData <- make_eyetrackingr_data(testSubset3, 
                participant_column = "Subject",
                trial_column = "TRIAL_INDEX",
                time_column = "time",
                trackloss_column = "TrackLoss",
                aoi_columns = c('Target','CompetitorHigh','CompetitorLow','Distractor'),
                treat_non_aoi_looks_as_missing = FALSE)


response_time2 <- make_time_sequence_data(EyeData,
                        time_bin_size = 25, 
                        aois = c('Target','CompetitorHigh','CompetitorLow','Distractor'),
                        summarize_by = "Subject")

response_time2$AOI<-as.factor(response_time2$AOI)


```


```{r,cache=TRUE}
###########################Target vs Competitor Bootstrap Analysis
#filter out the competitor and the target
Filtered<-response_time2 %>% filter(AOI=="CompetitorHigh" | AOI=="CompetitorLow")
Filtered$AOI<-as.factor(as.character(Filtered$AOI))
Filtered$AOI<-relevel(Filtered$AOI, "CompetitorHigh")



#Bootsrapped cluster-based permutation analysis
#Find the number of subjects and the t-threshold 
num_sub = length(unique((Filtered$Subject)))
threshold_t = qt(p = 1 - .05/2, 
                 df = num_sub-1) # pick threshold t based on alpha = .05 two tailed
threshold_t

df_timeclust <- make_time_cluster_data(Filtered, 
                                      test= "t.test", paired=TRUE,
                                      predictor_column = "AOI",
                                      threshold = -threshold_t) 
tstat<-plot(df_timeclust) +  ylab("T-Statistic") + theme_light()
summary(df_timeclust)

registerDoParallel(3)
clust_analysis <- analyze_time_clusters(df_timeclust, samples=10000, within_subj=TRUE, paired=TRUE) #

distribution<-plot(clust_analysis) + theme_light()

```

```{r}
plotExp1<-grid.arrange(tstat, distribution, nrow=1, ncol=2)
grid.arrange(tstat, distribution, nrow=1, ncol=2)

ggsave(
  "HighvsLowCompExp2.png",
  plotExp1,
  width = 9.25,
  height = 6.25,
  dpi = 300
)

summary(clust_analysis)
```


Session Info
```{r}
sessionInfo()
```